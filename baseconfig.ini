[model]
# max length of the couplet in the training data
max_len = 8
# max number of characters in the vocabulary (ordered by count desc)
max_char = 6000
# embedding dimension
embedding_dim = 128
# number of units in the encoder/decoder model
units = 1024
# number of layers in the encoder/decoder
num_layers = 4
# dropout
dropout = 0.2

[io]
# the couplet files
input_file = drive/My Drive/couplets/in.txt
output_file = drive/My Drive/couplets/out.txt
# the vocabulary file
vocab_file = drive/My Drive/couplets/vocabs.txt
# char2idx and idx2char path to read and/or save
char2idx_path = drive/My Drive/couplets/training_checkpoints/char2idx.pkl
idx2char_path = drive/My Drive/couplets/training_checkpoints/idx2char.pkl
# the path to read/save the word2vec model
word2vec_path = drive/My Drive/couplets/training_checkpoints/word2vec_6000_128.model
# the checkpoint path where the model weights are stored
# the weights after the training will be saved in this path as well
model_weights_dir = drive/My Drive/couplets/training_checkpoints
# the directory to save checkpoints during the training
training_checkpoints_dir = ./training_checkpoints

[training]
# whether the word2vec model has already been pretrained
word2vec_pretrained = True
# whether to train from scratch or continue from a checkpoint
train_from_scratch = True
# the starting epoch
start_epoch = 0
# number of epochs to train
num_epoch = 10
# batch size
batch_size = 32
# learning rate
learning_rate = 0.001
